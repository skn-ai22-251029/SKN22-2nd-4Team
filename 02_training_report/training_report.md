1# 상세 인공지능 학습 결과 보고서 (Detailed Training Report)

## 1. 모델링 프로세스 개요
본 프로젝트에서는 고객 이탈을 사전에 탐지하기 위해 다양한 머신러닝 알고리즘을 벤치마킹하고, 최적의 모델을 선정하여 파라미터 튜닝을 진행했습니다. 특히 실험을 통해 데이터 전처리 방식과 불균형 데이터 처리 기법의 다양한 조합을 검증하여 최상의 성능을 도출했습니다.

## 2. 모델 알고리즘 비교 (Benchmark)
- **실험 대상**: Decision Tree, Random Forest, XGBoost, LightGBM, CatBoost, ANN, SVM, Logistic Regression
- **평가 기준**: 동일한 Test Set (Support 638)에서 F1-Score 및 Recall 지표 비교
- **주요 결과**:
  - 트리 기반 앙상블 모델(XGBoost, CatBoost, LightGBM)이 전반적으로 우수한 성능을 기록했습니다.
  - 특히 **CatBoost**는 라벨 인코딩과 결합했을 때 정밀도와 재현율의 완벽한 균형을 보이며 가장 높은 F1-Score를 기록하여 최종 모델로 선정되었습니다.

## 3. 최종 모델 선정: CatBoost
### 3.1. 선정 사유 (Rationale)
1.  **원-핫 인코딩(OHE)과의 시너지**: 카테고리 개수가 적은 변수 특성상, 자체 처리 방식보다 원-핫 인코딩을 통해 각 범주를 독립된 피처로 분리했을 때 모델이 이탈 패턴을 더 명확하게 식별했습니다.
2.  **원본 데이터 패턴 유지 (No Weights)**: `class_weight='balanced'`나 SMOTE를 적용하지 않았을 때 가장 높은 성능이 관찰되었습니다. 이는 인위적인 보정 없이 원본 데이터의 순수한 패턴을 학습함으로써 오탐(False Positive)을 최소화하고 정밀도를 극대화할 수 있었기 때문입니다.
3.  **실전적 예측 성능**: 이탈자 중 72명을 정확히 검출하면서도 오탐은 단 2건에 불과한 압도적인 변별력을 보였습니다.

## 4. 하이퍼파라미터 최적화 (Optuna Tuning)
- **최적화 도구**: Optuna 프레임워크 사용
- **데이터 처리**: 이진 변수를 제외한 모든 범주형 변수에 라벨 인코딩 적용 및 가중치 미적용
- **최적 파라미터**:
  - `bagging_temperature`: 0.5142344384136116
  - `depth`: 8
  - `colsample_bylevel`: 0.5232252063599989

## 5. 최종 성능 지표 (Final Evaluation)
최종 학습된 CatBoost 모델의 테스트 데이터(Support 638) 기준 실측 성능입니다.

| 지표 (Metric) | 결과 (Result) | 비고 |
| :--- | :--- | :--- |
| **F1-Score (Optimized)** | **0.88** | 정밀도와 재현율의 조화 평균 |
| **Recall (재현율)** | **0.80** |-9856 (오탐 단 2건) |
| **ROC AUC** | **0.9117** | 모델의 전반적인 분류 판별 성능 |
| **Optimal Threshold** | **0.36** | 비즈니스 효율을 극대화하는 확률 임계값 |

## 6. 결론 및 향후 계획
- 본 모델은 불균형 데이터 환경에서도 별도의 가중치 보정 없이 **원-핫 인코딩과 CatBoost의 결합**만으로 97%의 높은 정밀도와 80%의 재현율을 동시에 확보했습니다.
- 인위적인 샘플링이나 가중치 부여가 오히려 모델의 노이즈를 증가시킬 수 있음을 실험적으로 증명하였으며, 이에 따라 원본 데이터의 특징을 가장 잘 보존한 현재의 모델을 최종 선정하였습니다.
- 추후 실제 서비스 환경에서 수집되는 최신 데이터를 바탕으로 원-핫 인코딩된 피처들의 영향력을 지속적으로 모니터링하고 모델을 고도화할 예정입니다.