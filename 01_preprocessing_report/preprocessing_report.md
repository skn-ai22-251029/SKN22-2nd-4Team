## 1. 프로젝트 개요 및 데이터 소스
- **데이터 소스**: `data/01_raw/train.csv` (4,250 rows)
- **타겟 변수**: `churn` (이탈 여부)
- **초기 상태**: 약 14%의 고객이 이탈한 불균형 데이터셋.

## 2. 데이터 통합 및 세정 (Data Cleaning)
- **병합 전략**: 초기에는 `train.csv`와 `test.csv`를 병합하여 일관된 인코딩을 적용했으나, `test.csv`에 실제 레이블(Label)이 없는 것을 확인하여 최종적인 모델 학습 및 검증은 레이블이 있는 4,250개의 데이터를 기반으로 재구성했습니다.
- **불필요 변수 제거**: 모델 성능에 영향을 주지 않는 고유 식별자(`id`) 및 관리용 변수(`dataset_source`)를 제거했습니다.

## 3. 피처 엔지니어링 및 인코딩 (Feature Engineering)
### 3.1. 이진 매핑 (Binary Mapping)
- 문자열로 구성된 이진 변수들을 수치형(1/0)으로 변환하여 모델의 수렴 속도와 연산 효율을 높였습니다.
  - 대상: `international_plan`, `voice_mail_plan`, `churn`
  - 변환: `{'yes': 1, 'no': 0}`

### 3.2. 범주형 변수 처리 (Encoding)
- **최종 선택: 원-핫 인코딩 (One-Hot Encoding)**
- **사유**: CatBoost의 자체 범주형 처리 방식보다 원-핫 인코딩을 통해 각 범주를 독립된 이진 피처로 분리했을 때 모델이 더 명확한 결정 경계를 형성했습니다. 특히 카테고리 개수가 적은 변수 특성상, 직접적인 피처 분리가 모델의 식별력을 높여 성능 향상(F1 0.88)을 이끌어냈습니다.

## 4. 이상치 처리 (Outlier Handling)
- **탐지 기법**: IQR (Interquartile Range) 방식 적용.
- **결정**: 특정 지표(사용 시간, 요금 등)에서 발생하는 극단적인 값들이 실제 고객의 사용 패턴을 반영하고 있다고 판단하여, **최종 파이프라인에서는 이상치를 제거하지 않고 보존**했습니다. 이는 이탈 징후를 보이는 고유 패턴을 유지하기 위함입니다.

## 5. 데이터 분할 전략 (Data Splitting Strategy)
- **방식**: **층화 분할 (Stratified Split)**
- **분할 비율**: Train 85% / Test 15%
- **표본 수**:
  - **학습용 (Train Set)**: 3,612개
  - **검증용 (Test Set)**: **638개**
- **정당성**: 모든 벤치마킹 실험의 공통 기준으로 **Support 638개**를 사용함으로써 모델 간 비교의 객관성을 확보했습니다.
`
## 6. 클래스 불균형 해결 (Imbalance Mitigation)
### 6.1. 샘플링 파이프라인 실험
- 불균형 문제를 해결하기 위해 SMOTE, SMOTE-Tomek, SMOTE-ENN 등의 기법을 적용 및 실험했으나, 최종 모델링에서는 제외되었습니다.

### 6.2. 최종 선택: 원본 데이터 유지 및 가중치 미적용 (No Class Weights)
- **실험 결과**: 가중치를 적용한 모델(F1 0.86)보다 **가중치를 적용하지 않은 모델(F1 0.88)**의 성능이 더 우수하게 나타났습니다.
- **선정 사유**: 
  - **패턴의 명확성**: 데이터 내 이탈 시그널이 충분히 뚜렷하여, 인위적인 가중치 보정 없이도 모델이 효과적으로 학습했습니다.
  - **정밀도 유지**: 가중치를 부여할 경우 발생하는 정밀도(Precision) 급락을 방지하여, 최종적으로 **97%의 높은 정밀도**와 **80%의 재현율**을 동시에 확보했습니다.
  - **노이즈 방지**: 인위적인 샘플링이나 가중치 부여가 오히려 모델에 편향(Bias)을 유발할 수 있음을 확인하여, 원본 데이터의 특성을 그대로 활용하는 방식을 최종 채택했습니다.
